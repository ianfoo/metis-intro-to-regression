{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project: Using Python to read a document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has a huge array of interesting things you can do with it. So far, we've stuck mostly to exercises to test your compreshension, but now let's branch into actually doing something useful. Let's start out by building a word counter. In this project, I'm not going to give you much guidance - I'm just going to tell you what you need to accomplish and then let you get to work. So here's the goal:\n",
    "\n",
    "I'd like to take a document of words like, \"the dog ran to the store\" and have python count the words and tell me how many of each word is in the document. So I'd like the output of my efforts on the above line to be a python object that tells me:\n",
    "\n",
    "* the - 2\n",
    "* dog - 1\n",
    "* ran - 1\n",
    "* to - 1\n",
    "* store - 2\n",
    "\n",
    "Make it happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:11:39.954728Z",
     "start_time": "2018-04-03T15:11:39.951609Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_phrase = 'the dog ran to the store'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once you have this working, you'll need to do some text cleanup. What happens if you have the words: 'dog?' and 'dog'? Are they treated the same way? What about \"Dog\" and \"dog\"? You'll need to write some code to clean up the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:11:41.773656Z",
     "start_time": "2018-04-03T15:11:41.770333Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_phrase = 'The dog ran to the store!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's write a function to find the most common word, given a vocabulary with words and counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus question 1: Allow your pipeline to read from text documents. \n",
    "\n",
    "Note that this adds some complexity because now you have to worry about line breaks and file names and how do you read lines, etc. Use the provided data file and create a word count for parts of the first chapter of Dracula!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:11:45.105729Z",
     "start_time": "2018-04-03T15:11:45.102357Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"./data/dracula_chapter1_excerpt.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus question 2: Extend your methodology so that if I feed in a list of documents, you can create a word count across all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:11:48.530112Z",
     "start_time": "2018-04-03T15:11:48.526878Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = ['the dog ran to the store','the quick brown fox jumped over the lazy dog',\n",
    "             'how many roads must a man walk down? 42.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus question 3: Right now we're only counting each individual word in the document. I'm also interested to know how often pairs of words appear. Find a way to count not just individual words, but also pairs. \n",
    "\n",
    "So in our original example of \"the dog ran to the store\" we'd now have a result of:\n",
    "\n",
    "* the - 2\n",
    "* dog - 1\n",
    "* ran - 1\n",
    "* to - 1\n",
    "* store - 1\n",
    "* the dog - 1\n",
    "* dog ran - 1\n",
    "* ran to - 1\n",
    "* to the - 1\n",
    "* the store - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T15:11:53.649824Z",
     "start_time": "2018-04-03T15:11:53.646758Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_phrase = 'the dog ran to the store'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
